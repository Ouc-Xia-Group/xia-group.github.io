---
title: 实验室论文被Knowledge-Based Systems录用
date: 2025-08-13
layout: news_info
re: true
---

聚焦大型语言模型（LLMs）在边缘设备部署时面临的越狱攻击问题，2025年8月13日，24级博士研究生康姿在夏辉教授的指导下发表论文Fast and Controllable Bias-Guided Jailbreak Attack on Large Language Models，成功被IEEE Internet of Things Journal期刊录用。论文指出现有攻击方案生成高隐蔽性越狱提示词效率低下的问题，提出快速可控的偏见引导越狱攻击（FCB）方案：一是优化模型输出层偏见，通过直接调整输出层对数几率，引导生成低能耗越狱提示词，加速解码；二是设计令牌停止选择和偏见归一化方法，约束迭代过程中的扰动，避免生成无意义语义的提示词，增强隐蔽性。该研究揭示了在资源受限的边缘设备上，LLM安全防护的脆弱性，为业界构建更鲁棒的端侧大模型防御策略提供了关键的攻击视角与思路。